{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1eda934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "#graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#building models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b75f6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"НЕ ЗАБУДЬТЕ:\n",
    "- отсортировать df по дате.\n",
    "- перевести значения колонки в int or float.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def occ(x: list):\n",
    "    c = Counter(x)\n",
    "    c = dict(sorted(c.items(), key=lambda item: item[1]))\n",
    "    res = list(c.keys())[-1]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def days_agg(dataframe: pd.DataFrame, column_name: str, agg_func: str, days: int):\n",
    "    \"\"\"Агрегирует данные в выбранной колонке за заданное колчество дней. По сути юзер-френдли 'скользящее окно'.\n",
    "\n",
    "    params agg_func: модет принимать значение ['mean', 'std', 'sum', 'amplitude', 'occ'].\n",
    "        - amplitude: max(value) - min(value)\n",
    "        - occ: максимальное встречающееся значение\n",
    "            [2,3,4,2,2,2,3]: {2: 4, 3: 2, 4: 1} => вернет 2, максимально встречающееся значение\n",
    "    params days: ширина окна\n",
    "    params column_name: что агрегировать\n",
    "    params dataframe: dataframe\n",
    "\n",
    "    return: ...\n",
    "    \"\"\"\n",
    "\n",
    "    d = {\n",
    "        'mean': np.mean,\n",
    "        'sum': np.sum,\n",
    "        'std': np.std,\n",
    "        'amplitude': lambda x: np.max(x) - np.min(x),\n",
    "        'occ': occ\n",
    "    }\n",
    "\n",
    "    agg_f = d[agg_func]\n",
    "    values = np.array(dataframe[column_name])\n",
    "    result = []\n",
    "\n",
    "    for i in range(0, len(values)):\n",
    "        i_ = i - days\n",
    "        if i_ < 0:\n",
    "            i_ = 0\n",
    "        \n",
    "        result.append(agg_f(values[i_:i+1]))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90791795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ts_to_table(idx, time_series, window_size):\n",
    "    \"\"\" Method convert time series to lagged form.\n",
    "    :param idx: the indices of the time series to convert\n",
    "    :param time_series: source time series\n",
    "    :param window_size: size of sliding window, which defines lag\n",
    "    :return updated_idx: clipped indices of time series\n",
    "    :return features_columns: lagged time series feature table\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert data to lagged form\n",
    "    lagged_dataframe = pd.DataFrame({'t_id': time_series})\n",
    "    vals = lagged_dataframe['t_id']\n",
    "    for i in range(1, window_size + 1):\n",
    "        frames = [lagged_dataframe, vals.shift(i)]\n",
    "        lagged_dataframe = pd.concat(frames, axis=1)\n",
    "\n",
    "    # Remove incomplete rows\n",
    "    lagged_dataframe.dropna(inplace=True)\n",
    "\n",
    "    transformed = np.array(lagged_dataframe)\n",
    "\n",
    "    # Generate dataset with features\n",
    "    features_columns = transformed[:, 1:]\n",
    "    features_columns = np.fliplr(features_columns)\n",
    "\n",
    "    return idx, features_columns\n",
    "\n",
    "def convert_wated_codes(value):\n",
    "    values = list(map(int, map(lambda x: x.strip(), value.split(','))))\n",
    "    res = 0\n",
    "    \n",
    "    for val in values:\n",
    "        res += water_codes[water_codes['water_code'] == val].reset_index(drop=True).iloc[0][1]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def feature_aggregation(new_df):\n",
    "    columns = new_df.columns\n",
    "    columns_drop = []\n",
    "\n",
    "    if 'discharge' in columns:\n",
    "        new_df['discharge_mean'] = days_agg(new_df, 'discharge', 'mean', 4)\n",
    "        columns_drop.append('discharge')\n",
    "    if 'stage_avg' in columns:\n",
    "        new_df['stage_avg_amplitude'] = days_agg(new_df, 'stage_avg', 'amplitude', 7)\n",
    "        new_df['stage_avg_mean'] = days_agg(new_df, 'stage_avg', 'mean', 4)\n",
    "        columns_drop.append('stage_avg')\n",
    "    if 'snow_coverage_station' in columns:\n",
    "        new_df['snow_coverage_station_amplitude'] = days_agg(new_df, 'snow_coverage_station', 'amplitude', 7)\n",
    "        columns_drop.append('snow_coverage_station')\n",
    "    if 'snow_height' in columns:\n",
    "        new_df['snow_height_mean'] = days_agg(new_df, 'snow_height', 'mean', 4)\n",
    "        new_df['snow_height_amplitude'] = days_agg(new_df, 'snow_height', 'amplitude', 7)\n",
    "        columns_drop.append('snow_height')\n",
    "    if 'precipitation' in columns:\n",
    "        new_df['precipitation_sum'] = days_agg(new_df, 'precipitation', 'sum', 30)\n",
    "        columns_drop.append('precipitation')\n",
    "    if 'water_hazard' in columns:\n",
    "        new_df['water_hazard_sum'] = days_agg(new_df, 'water_hazard', 'sum', 2)\n",
    "        columns_drop.append('water_hazard')\n",
    "\n",
    "    new_df.drop(columns_drop, axis=1, inplace=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eea3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac94babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [3019, 3027, 3028, 3030, 3035, 3041, 3045, 3230, 3050, 3029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cea8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub_1 = pd.read_csv('./submissions/sample_submissions/sample_sub_1.csv')\n",
    "sample_sub_2 = pd.read_csv('./submissions/sample_submissions/sample_sub_2.csv')\n",
    "sample_sub_3 = pd.read_csv('./submissions/sample_submissions/sample_sub_3.csv')\n",
    "sample_sub_4 = pd.read_csv('./submissions/sample_submissions/sample_sub_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbe417d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_code</th>\n",
       "      <th>hazard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   water_code   hazard\n",
       "0           1        0\n",
       "1           2        0\n",
       "2           3        0\n",
       "3           4        0\n",
       "4           5        0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_codes = pd.read_csv('./data/misc/ref_code_hazard.csv')\n",
    "water_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eae966e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(id_, sample_sub):\n",
    "    meteo_prep = pd.read_csv(f'./data/meteo_data/no_gap_meteo_3hour_int_{id_}_wind.csv')\n",
    "    meteo_prep.drop(['station_id'], inplace=True, axis=1)\n",
    "    \n",
    "    meteo = pd.read_csv(f'./data/meteo_data/no_gap_meteo_1day_int_{id_}.csv')\n",
    "    meteo.drop(['station_id'], inplace=True, axis=1)\n",
    "    meteo.columns = ['date', 'snow_coverage_station', 'snow_height']\n",
    "    \n",
    "    train = pd.read_csv(f'./data/4rd_checkpoint/sub_datasets_no_gaps/no_gaps/no_gap_train_{id_}.csv')\n",
    "    train = train.set_index('date')\n",
    "    train['water_hazard'] = train['water_code'].fillna('1').apply(convert_wated_codes)\n",
    "    train.drop(['stage_min', 'stage_max', 'temp', 'water_code', 'station_id', 'ice_thickness',\n",
    "                'snow_height', 'place', 'year', 'month', 'day', 'delta_stage_max'], axis=1, inplace=True)\n",
    "    \n",
    "    columns = ['0_day', '1_day', '2_day', '3_day', '4_day', '5_day', '6_day', '7_day']\n",
    "    target_column = 'stage_avg'\n",
    "\n",
    "    a = train[target_column]\n",
    "    window_size = 8\n",
    "    idx = np.arange(train.shape[0] - window_size) + 1\n",
    "    idx, b = _ts_to_table(idx, a, window_size)\n",
    "\n",
    "    train = train.iloc[:-window_size, :]\n",
    "\n",
    "    new_df = pd.DataFrame(data=b, columns=columns, index=a.index[:-window_size])\n",
    "    new_df = pd.concat([train, new_df], axis=1, join='inner')\n",
    "    new_df.drop(['0_day'], axis=1, inplace=True)\n",
    "    \n",
    "    new_df = pd.merge(meteo_prep, new_df, how='inner', on=['date'])\n",
    "    new_df = pd.merge(meteo, new_df, how='inner', on=['date'])\n",
    "    new_df.drop(['wind_direction', 'wind_speed_aver'], axis=1, inplace=True)\n",
    "    \n",
    "    predictions = []\n",
    "    columns = ['1_day', '2_day', '3_day', '4_day', '5_day', '6_day', '7_day']\n",
    "    \n",
    "    for index in range(0, len(sample_sub['date']), 7):\n",
    "        mini_df = new_df[new_df['date'] < sample_sub['date'][index]]\n",
    "        mini_df = feature_aggregation(mini_df)\n",
    "        mini_df.drop(['date'], inplace=True, axis=1)\n",
    "\n",
    "        features = np.array(mini_df.drop(columns, axis=1))\n",
    "        features_test = np.array(mini_df.drop(columns, axis=1).iloc[-1, :]).reshape(1, -1)\n",
    "        target = np.array(mini_df[columns])\n",
    "\n",
    "        model = MultiOutputRegressor(lgb.LGBMRegressor(random_state=42), n_jobs=-1)\n",
    "        model.fit(features, target)\n",
    "        pred = model.predict(features_test)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b104bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = sample_sub_4['station_id'].unique()\n",
    "dfs = {}\n",
    "\n",
    "for id_ in station_ids:\n",
    "    sample_sub = sample_sub_4[sample_sub_4['station_id'] == id_].reset_index(drop=True)\n",
    "    predictions = predict(id_, sample_sub)\n",
    "    sample_sub['delta_stage_max'] = np.concatenate(np.concatenate(predictions))\n",
    "    dfs[id_] = sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b7e3937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0.353349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0.353349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>-0.793318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>18.742820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>-6.868219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>-5.526033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>49.909082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>-24.173369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>-20.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>3.179915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  station_id  month  day        date  delta_stage_max\n",
       "0    1993        3019      4  111  1993-04-21         0.353349\n",
       "1    1993        3019      4  112  1993-04-22         0.353349\n",
       "2    1993        3019      4  113  1993-04-23        -0.793318\n",
       "3    1993        3019      4  114  1993-04-24        18.742820\n",
       "4    1993        3019      4  115  1993-04-25        -6.868219\n",
       "..    ...         ...    ...  ...         ...              ...\n",
       "247  2013        3230      5  134  2013-05-14        -5.526033\n",
       "248  2013        3230      5  135  2013-05-15        49.909082\n",
       "249  2013        3230      5  136  2013-05-16       -24.173369\n",
       "250  2013        3230      5  137  2013-05-17       -20.934579\n",
       "251  2013        3230      5  138  2013-05-18         3.179915\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat(dfs.values())\n",
    "stage = []\n",
    "predictions = submission['delta_stage_max'].reset_index(drop=True)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if i % 7 == 0:\n",
    "        stage.append(predictions[i + 1] - predictions[i])\n",
    "    else:\n",
    "        stage.append(predictions[i] - predictions[i - 1])\n",
    "        \n",
    "submission['delta_stage_max'] = stage\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c8a4cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_4_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abc5da",
   "metadata": {},
   "source": [
    "## MODELING, ENSEMBLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b216b32",
   "metadata": {},
   "source": [
    "### FEDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "55e0924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedot.api.main import Fedot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "columns = ['discharge_mean', 'stage_avg_amplitude', 'stage_avg_mean', 'snow_coverage_station_amplitude',\n",
    "           'snow_height_mean', 'snow_height_amplitude', 'precipitation_sum', 'water_hazard_sum']\n",
    "\n",
    "\n",
    "composer_params = {'max_depth': 5,\n",
    "                   'max_arity': 7,\n",
    "                   'pop_size': 5,\n",
    "                   'num_of_generations': 20,\n",
    "                   'learning_time': 10,\n",
    "                   'with_tuning': True}\n",
    "\n",
    "model = Fedot(problem='regression', preset='light', learning_time=13, composer_params=composer_params, seed=42)\n",
    "model.fit(features=new_df.drop(columns, axis=1), target=columns)\n",
    "pred = model.predict()\n",
    "predictions.append(pred.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b6c60",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d91fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867172ef",
   "metadata": {},
   "source": [
    "### LightAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "69b9dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.base import AutoML\n",
    "from lightautoml.ml_algo.boost_lgbm import BoostLGBM\n",
    "from lightautoml.ml_algo.tuning.optuna import OptunaTuner\n",
    "from lightautoml.automl.blend import WeightedBlender\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3c38497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('reg')\n",
    "reader = PandasToPandasReader(task, cv=5, random_state=1)\n",
    "\n",
    "model1 = BoostLGBM(default_params={'learning_rate': 0.1, 'num_leaves': 128, 'seed': 1, 'num_threads': 5})\n",
    "params_tuner2 = OptunaTuner(n_trials=100, timeout=100)\n",
    "model2 = BoostLGBM(default_params={'learning_rate': 0.05, 'num_leaves': 64, 'seed': 2, 'num_threads': 5})\n",
    "gbm_0 = BoostCB()\n",
    "gbm_1 = BoostCB()\n",
    "tuner_0 = OptunaTuner(n_trials=100, timeout=100, fit_on_holdout=True)\n",
    "\n",
    "\n",
    "pipeline_lvl1 = MLPipeline([model1, (model2, params_tuner2), (gbm_0, tuner_0), gbm_1])\n",
    "reg_2 = LinearLBFGS()\n",
    "pipeline_lvl2 = MLPipeline([reg_2])\n",
    "\n",
    "predictions = []\n",
    "\n",
    "\n",
    "timer = PipelineTimer(600, mode=2)\n",
    "automl = AutoML(reader, [\n",
    "    [pipeline_lvl1],\n",
    "    [pipeline_lvl2],\n",
    "], skip_conn=False, blender=WeightedBlender(), timer=timer)\n",
    "pred = automl.fit_predict(new_df.drop(columns, axis=1), roles={'target': columns})\n",
    "predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b413b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9b169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3562a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdcb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e59668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>delta_stage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>1993-04-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1993-04-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>113</td>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>1993-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>3019</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>1993-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2013</td>\n",
       "      <td>3230</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  station_id  month  day        date  delta_stage_max\n",
       "0     1993        3019      4  111  1993-04-21                0\n",
       "1     1993        3019      4  112  1993-04-22                0\n",
       "2     1993        3019      4  113  1993-04-23                0\n",
       "3     1993        3019      4  114  1993-04-24                0\n",
       "4     1993        3019      4  115  1993-04-25                0\n",
       "...    ...         ...    ...  ...         ...              ...\n",
       "2480  2013        3230      5  134  2013-05-14                0\n",
       "2481  2013        3230      5  135  2013-05-15                0\n",
       "2482  2013        3230      5  136  2013-05-16                0\n",
       "2483  2013        3230      5  137  2013-05-17                0\n",
       "2484  2013        3230      5  138  2013-05-18                0\n",
       "\n",
       "[2485 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_4 = pd.read_csv('./submissions/sample_submissions/sample_sub_4.csv')\n",
    "sample_sub_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4697b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = sample_sub_4['station_id'].unique()\n",
    "dfs = {}\n",
    "\n",
    "for id_ in station_ids:\n",
    "     dfs[id_] = sample_sub_4[sample_sub_4['station_id'] == id_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d857064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ids = [3019, 3027, 3028, 3030, 3035, 3041, 3045, 3230, 3050, 3029]\n",
    "results = []\n",
    "\n",
    "\n",
    "for id_ in ids:\n",
    "    with open(f'predictions{id_}.pkl', 'rb') as f:\n",
    "        array = pickle.load(f)\n",
    "        results.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa381e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a09c20e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36.59279675,  34.31469746,  45.79399691, ..., 438.67104222,\n",
       "       424.5675937 , 419.17649831])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(np.concatenate(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a263c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-666cf23d6f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (7,) "
     ]
    }
   ],
   "source": [
    "q = []\n",
    "\n",
    "for a in results[0]:\n",
    "    print(type(a[0]))\n",
    "    q += a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a07b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
